# 5/2 System Design Interview

Date: May 2, 2022 5:09 AM

## 사용자 수에 따른 규모 확장성

### 단일 서버

- 최초에 사용자가 많이 없는 경우 웹앱, 데이터베이스, 캐시 등이 전부 서버 하나에서 실행된다.

### 데이터베이스

- 사용자가 늘면 DB 서버를 분리하면 독립적으로 확장이 가능하다
- 대부분의 경우 RDBMS가 최선이지만 아래와 같은 경우 NoSQL을 고려해볼 것
    - 아주 낮은 응답 지연시간이 요구됨
    - 다루는 데이터가 비정형
    - 데이터를 직렬화하거나 역직렬화 할 수 있기만 하면 됨
    - 아주 많은 양의 데이터를 저장할 필요가 있음

### 수직적 규모 확장 vs 수평적 규모 확장

- 스케일 업(scale up) - 수직적 규모 확장(verical scaling)
    
    : 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM)을 추가하는 행위
    
    - 단점
        - 한대의 서버에 CPU나 메모리 확장에는 한계가 있다
        - 자동복구 방안이나 다중화 방안을 제시하지 않는다. 장애 발생시 서비스 중단
- 스케일 아웃(scale out) - 수평적 규모 확장
    
    : 더 많은 서버를 추가하여 성능을 개선
    

### 로드밸런서

- 부하 분산 집합(load balancing set)에 속한 웹 서버들에 트래픽을 고르게 분산하는 역할
- 사용자는 로드밸런서의 공개 IP주소로 접속한다.
- 로드밸런서가 웹서버와 통신하는 경우 사설 IP주소를 주로 이용한다.
- 서버 1 다운시 트래픽을 서버 2로 전송되므로 서비스가 중단되지 않는다.
- 트래픽 증가시 웹 서버 계층에 더 많은 서버만 추가하면 된다.

### 데이터베이스 다중화

- 서버 사이에 master-slave 관계를 설정하고 데이터 원본은 master에 사본은 slave에 저장한다.
- 쓰기 연산은 마스터에서만 지원
- slave에서는 그 사본을 전달 받아 읽기 연산만 지원
- 통상 읽기 연산의 비중이 쓰기 연산보다 높아 slave DB 수가 더 많다.
- 장점
    - 성능 : 병렬로 처리될 수 있는 Query가 늘어나므로 성능이 좋아짐.
    - 안정성 : 서버 일부가 파괴되어도 데이터가 보존된다.
    - 가용성 : 장애 발생시 다른 서버에 있는 데이터를 가져와 서비스가 계속될 수 있도록 한다.

### 캐시

- 캐시는 값비싼 연산결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소다.
- 캐시 계층(cache tier)
    - 데이터가 잠시 보관되는 곳으로 DB보다 훨씬 빠르다.
    - DB의 부하를 줄일 수 있다.
- 읽기 주도형 캐시 전략(read-through caching strategy)
    - 캐시에 요청에 해당하는 데이터가 있는지 확인 하고 있으면 바로 반환, 없는 경우 DB에 요청하는 전략
- 캐시 사용시 유의할 점
    - 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어나는 경우
    - 캐시는 휘살벙 메모리이므로 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다.
    - 캐시의 특성에 따라 만료기한을 잘 설정해줘야 한다.
    - 데이터 저장소의 원본과 캐시 내의 사본과의 일관성이 유지되는가?
    - 캐시 서버를 한 대만 두는 경우 장애에는 어떻게 대처할 것인가? -  SPOF가 될 수 있다.
    - 메모리의 크기는 어떻게 잡을 것인가?
    - 데이터 방출 정책 - 캐시가 꽉 차버리면 추가로 캐시를 넣어야 할 경우 기존 데이터를 어떤 방식으로 방출할 것인가?